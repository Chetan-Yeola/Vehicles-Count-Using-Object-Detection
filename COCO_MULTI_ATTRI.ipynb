{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "COCO_MULTI_ATTRI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Tp8Haj_Ltn"
      },
      "source": [
        "#Install dependancies and latest versions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iidM1ICaA9zB",
        "outputId": "3df9a1e0-2c64-4e51-8a62-26e108fdffe3"
      },
      "source": [
        "!pip install opencv-python==4.5.3.56 "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python==4.5.3.56\n",
            "  Downloading opencv_python-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.9 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.3.56) (1.21.6)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-python-4.5.3.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "614vNP_UBBp0"
      },
      "source": [
        "##Restart Kernel "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK9SdWjXL7Kr"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ5lxibn_jGV"
      },
      "source": [
        "#Mount your drive for external storage "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwjQ-7agL79y",
        "outputId": "7cc88b75-cb18-44bc-dc9c-9d5e44f5fb72"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7P9RsFdBLY8"
      },
      "source": [
        "##Define function for people Counting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry-FJw5AnKHV"
      },
      "source": [
        "\n",
        "def People_Count(img):\n",
        " \n",
        "  !pip install inflection\n",
        "\n",
        "  import inflection    # Camel Case\n",
        "  import cv2\n",
        "  import numpy as np\n",
        "  from google.colab.patches import cv2_imshow\n",
        "  from imutils.video import FPS\n",
        "  import json\n",
        "  import time\n",
        "\n",
        "  def camel(string):\n",
        "    return inflection.camelize(string, False)\n",
        "  #CONFIG_FILE = .cfg file for COCO \n",
        "  #WEIGHTS_FILE = .weight file for YOLO v4 by COCO dataset\n",
        "  #COCO.names = .names file which includes all class names \n",
        "\n",
        "  # To read darknet module using config file and yolov3 weights\n",
        "  net = cv2.dnn.readNet(\"/content/drive/MyDrive/weights/yolov4.weights\", \"yolov4 (1).cfg\")\n",
        "  classes = []\n",
        "  with open(\"/content/coco.names\", \"r\") as f:\n",
        "      classes = [line.strip() for line in f.readlines()]\n",
        "  layer_names = net.getLayerNames()\n",
        "  output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "  colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        " # Determine number of classes \n",
        "\n",
        "  classes = []\n",
        "\n",
        "  with open('/content/coco.names') as cls:\n",
        "    classes = cls.read().splitlines()\n",
        "\n",
        "  #print(classes)\n",
        "####################    FOR VIDEO UNCOMMENT THIS   ##################################\n",
        "  # cap = cv2.VideoCapture(\"/content/6.mp4\")\n",
        "  # codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "  # fps =int(cap.get(cv2.CAP_PROP_FPS))\n",
        "  # cap_width,cap_height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  # output= cv2.VideoWriter('adpp_is_out_6rd.mp4', codec, fps, (cap_width, cap_height), True)\n",
        "\n",
        "  # fps= FPS().start()\n",
        "\n",
        "  # frame_id = 0\n",
        "\n",
        "  # while True:\n",
        "  #   #reading video frame by frame and checking for its null condition\n",
        "  #   _, img= cap.read()\n",
        "    p = 0  \n",
        "  #   frame_id+=1\n",
        "  #   if img is None:\n",
        "  #     print('Completed')\n",
        "  #     break\n",
        "    # getting output layer of darknet\n",
        "\n",
        "###############################################################################\n",
        "    height, width,_ = img.shape\n",
        "    blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    out_names= net.getUnconnectedOutLayersNames()\n",
        "    layerOutputs = net.forward(out_names)\n",
        "\n",
        "    # generating detection in the form of bounding box, confidence and class id\n",
        "    boxes=[]\n",
        "    confidences=[]\n",
        "    class_ids=[]\n",
        "\n",
        "    for out in layerOutputs:\n",
        "      for detection in out:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "        if confidence > 0.3:\n",
        "          centerX= int(detection[0]* width)\n",
        "          centerY= int(detection[1]* height)\n",
        "          w= int(detection[2]* width)\n",
        "          h= int(detection[3]* height)\n",
        "          x = int(centerX - (w/ 2))\n",
        "          y = int(centerY - (h/ 2))\n",
        "\n",
        "          boxes.append([x, y, w, h])\n",
        "          confidences.append(float(confidence))\n",
        "          class_ids.append(class_id)\n",
        "\n",
        "    indexes= cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.4)\n",
        "    indexes= np.array(indexes)\n",
        "    font= cv2.FONT_HERSHEY_PLAIN\n",
        "    colors= np.random.uniform(0, 255, size=(len(boxes),3))\n",
        "\n",
        "    #count_person = []\n",
        "\n",
        "    for i in indexes.flatten():\n",
        "      x, y, w, h= boxes[i]\n",
        "      label= str(classes[class_ids[i]])\n",
        "      if label == 'person':\n",
        "        p=p+1\n",
        "      else:\n",
        "        continue\n",
        "      confidence= str(round(confidences[i],2))\n",
        "      color= colors[i]\n",
        "      cv2.rectangle(img, (x, y), (x+w,y+h), color, 2)\n",
        "      text = label + ':' + str(p)\n",
        "      cv2.putText(img, text+\":\"+ confidence, (x, y+20), font, 1, (255, 255, 255), 2)\n",
        "\n",
        "    cv2.putText(img, camel(\"People Counter: \") + str(p) , (15, 25), font, 2.0, (255,0,0), 2)\n",
        "\n",
        "      # saving frame by frame detection and counting in video format\n",
        "    cv2_imshow(img)\n",
        "    #output.write(img)\n",
        "    key = cv2.waitKey(1)\n",
        "    #if key == 27:\n",
        "  #       break\n",
        "  #   fps.update()\n",
        "\n",
        "  # fps.stop()\n",
        "  # output.release()\n",
        "  # cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "wACObPsvoH6_",
        "outputId": "f0ccce05-2714-41c6-cb17-ea62e0d1ec91"
      },
      "source": [
        "img = cv2.imread('/content/pexels-pavel-danilyuk-7234287.jpg')\n",
        "\n",
        "People_Count(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting inflection\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: inflection\n",
            "Successfully installed inflection-0.5.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4096c5bce45b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/pexels-pavel-danilyuk-7234287.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mPeople_Count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-95efe552b389>\u001b[0m in \u001b[0;36mPeople_Count\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# To read darknet module using config file and yolov3 weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/weights/yolov4.weights\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"yolov4 (1).cfg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/coco.names\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.5.3) /tmp/pip-req-build-l1r0y34w/opencv/modules/dnn/src/darknet/darknet_importer.cpp:207: error: (-212:Parsing error) Failed to parse NetParameter file: yolov4 (1).cfg in function 'readNetFromDarknet'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3M6IEz8MkSl",
        "outputId": "81b87b63-35ea-4d26-8a90-70ba2cfc0088"
      },
      "source": [
        "# !pip install opencv-contrib-python==3.4.13.47 --force-reinstall\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "!pip install inflection\n",
        "\n",
        "import inflection    # Camel Case\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils.video import FPS\n",
        "import json\n",
        "import time\n",
        "\n",
        "def camel(string):\n",
        "  return inflection.camelize(string, False)\n",
        "\n",
        "#camel(\"hello_all\")\n",
        "\n",
        "# Determine number of classes \n",
        " # To read darknet module using config file and yolov3 weights\n",
        "net = cv2.dnn.readNet(\"/content/drive/MyDrive/Yolov4/yolov4.weights\", \"/content/drive/MyDrive/Yolov4/yolococo.cfg\")\n",
        "classes = []\n",
        "with open(\"/content/coco.names\", \"r\") as f:\n",
        "  classes = [line.strip() for line in f.readlines()]\n",
        "  layer_names = net.getLayerNames()\n",
        "  output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "  colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "classes = []\n",
        "\n",
        "with open('/content/coco.names') as cls:\n",
        "  classes = cls.read().splitlines()\n",
        "\n",
        "#print(classes)\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/Yolov4/pexels-christopher-schultz-5927708.mp4\")\n",
        "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "fps =int(cap.get(cv2.CAP_PROP_FPS))\n",
        "cap_width,cap_height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "output= cv2.VideoWriter('/content/drive/MyDrive/Yolov4/71_out_2.mp4', codec, fps, (cap_width, cap_height), True)\n",
        "\n",
        "fps= FPS().start()\n",
        "\n",
        "\n",
        "frame_id = 0\n",
        "\n",
        "while True:\n",
        "  #reading video frame by frame and checking for its null condition\n",
        "  _, img= cap.read()\n",
        "  p = 0  \n",
        "  q = 0\n",
        "  e = 0\n",
        "  r = 0\n",
        "  t = 0\n",
        "  frame_id+=1\n",
        "  if img is None:\n",
        "    print('Completed')\n",
        "    break\n",
        "  # getting output layer of darknet\n",
        "  height, width,_ = img.shape\n",
        "  blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
        "  net.setInput(blob)\n",
        "  out_names= net.getUnconnectedOutLayersNames()\n",
        "  layerOutputs = net.forward(out_names)\n",
        "\n",
        "  # generating detection in the form of bounding box, confidence and class id\n",
        "  boxes=[]\n",
        "  confidences=[]\n",
        "  class_ids=[]\n",
        "\n",
        "  for out in layerOutputs:\n",
        "    for detection in out:\n",
        "      scores = detection[5:]\n",
        "      class_id = np.argmax(scores)\n",
        "      confidence = scores[class_id]\n",
        "      if confidence > 0.3:\n",
        "        centerX= int(detection[0]* width)\n",
        "        centerY= int(detection[1]* height)\n",
        "        w= int(detection[2]* width)\n",
        "        h= int(detection[3]* height)\n",
        "        x = int(centerX - (w/ 2))\n",
        "        y = int(centerY - (h/ 2))\n",
        "\n",
        "        boxes.append([x, y, w, h])\n",
        "        confidences.append(float(confidence))\n",
        "        class_ids.append(class_id)\n",
        "\n",
        "  indexes= cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.4)\n",
        "  indexes= np.array(indexes)\n",
        "  font= cv2.FONT_HERSHEY_TRIPLEX\n",
        "  fnt = cv2.FONT_HERSHEY_PLAIN\n",
        "  colors= np.random.uniform(0, 255, size=(len(boxes),3))\n",
        "\n",
        "  #count_person = []\n",
        "\n",
        "  for i in indexes.flatten():\n",
        "    x, y, w, h= boxes[i]\n",
        "    label= str(classes[class_ids[i]])\n",
        "   \n",
        "    if label == 'bicycle':\n",
        "      p=p+1\n",
        "    elif label  == 'car':\n",
        "      q+=1\n",
        "    elif label == \"motorbike\":\n",
        "      e+=1\n",
        "    elif label == \"bus\":\n",
        "      r+=1\n",
        "    elif label == \"truck\":\n",
        "      t+=1\n",
        "    else:\n",
        "      continue\n",
        "    confidence= str(round(confidences[i],2))\n",
        "    color= colors[i]\n",
        "    cv2.rectangle(img, (x, y), (x+w,y+h), color, 2)\n",
        "    text1 = label + ':' + str(p)\n",
        "    text2 = label + ':' + str(q)\n",
        "    text3 = label + ':' + str(e)\n",
        "    text4 = label + ':' + str(r)\n",
        "    text5 = label + ':' + str(t)\n",
        "\n",
        "\n",
        "    cv2.putText(img, text1+\":\"+ confidence, (x, y+20), fnt, 2.5, (255, 255, 255), 2)\n",
        "    cv2.putText(img, text2+\":\"+ confidence, (x, y+20), fnt, 2.5, (255, 255, 255), 2)\n",
        "    cv2.putText(img, text3+\":\"+ confidence, (x, y+20), fnt, 2.5, (255, 255, 255), 2)\n",
        "    cv2.putText(img, text4+\":\"+ confidence, (x, y+20), fnt, 2.5, (255, 255, 255), 2)\n",
        "    cv2.putText(img, text5+\":\"+ confidence, (x, y+20), fnt, 2.5, (255, 255, 255), 2)\n",
        "\n",
        "\n",
        "\n",
        "  cv2.putText(img, camel(\"Bicycle Counter:  \") + str(p) , (10, 200), font, 2.5, (255, 255, 255), 2)\n",
        "  cv2.putText(img, camel(\"Car Counter:      \") + str(q) , (10, 270), font, 2.5, (255, 255, 255), 2)\n",
        "  cv2.putText(img, camel(\"Motorbike Counter:\") + str(e) , (10, 340), font, 2.5, (255, 255, 255), 2)\n",
        "  cv2.putText(img, camel(\"Bus Counter:      \") + str(r) , (10, 410), font, 2.5, (255, 255, 255), 2)\n",
        "  cv2.putText(img, camel(\"truck Counter:    \") + str(t) , (10, 480), font, 2.5, (255, 255, 255), 2)\n",
        "\n",
        "\n",
        "\n",
        "    # saving frame by frame detection and counting in video format\n",
        "  output.write(img)\n",
        "  key = cv2.waitKey(1)\n",
        "  if key == 27:\n",
        "      break\n",
        "  fps.update()\n",
        "\n",
        "fps.stop()\n",
        "output.release()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: inflection in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNvIEFDFhV_h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}